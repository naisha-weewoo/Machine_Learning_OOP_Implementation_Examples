{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f45ee9",
   "metadata": {},
   "source": [
    "#### [PREV](7.OOP_Neural_Network_Adv.ipynb) | [HOME](../README.md)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP Decision Trees Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997ebf8",
   "metadata": {},
   "source": [
    "In this notebook you will visualize how a decision tree is 'splitted' using information gain. This is a very complex implementation, students are not expected to write their own implementaion, but rather step through the Jupyter Notebook and deepen their understanding of 'information gain' and 'splitting' through the visual demononstration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768e8d5",
   "metadata": {},
   "source": [
    "#### Step 1 - Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a39309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae8231",
   "metadata": {},
   "source": [
    "#### Step 2: Preview The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb2280",
   "metadata": {},
   "source": [
    "|                                                     |   Ear Shape | Face Shape | Whiskers |   Cat  |\n",
    "|:---------------------------------------------------:|:---------:|:-----------:|:---------:|:------:|\n",
    "| <img src=\"images\\0.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |   Round     |  Present  |    1   |\n",
    "| <img src=\"images\\1.png\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Not Round  |  Present  |    1   |\n",
    "| <img src=\"images\\2.png\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Round      |  Absent   |    0   |\n",
    "| <img src=\"images\\3.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |  Not Round  |  Present  |    0   |\n",
    "| <img src=\"images\\4.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |   Round     |  Present  |    1   |\n",
    "| <img src=\"images\\5.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |   Round     |  Absent   |    1   |\n",
    "| <img src=\"images\\6.png\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Not Round  |  Absent   |    0   |\n",
    "| <img src=\"images\\7.png\" alt=\"drawing\" width=\"50\"/> |   Pointy   |  Round      |  Absent   |    1   |\n",
    "| <img src=\"images\\8.png\" alt=\"drawing\" width=\"50\"/> |    Floppy  |   Round     |  Absent   |    0   |\n",
    "| <img src=\"images\\9.png\" alt=\"drawing\" width=\"50\"/> |   Floppy   |  Round      |  Absent   |    0   |\n",
    "\n",
    "\n",
    "We will use **one-hot encoding** to encode the categorical features. They will be as follows:\n",
    "\n",
    "- Ear Shape: Pointy = 1, Floppy = 0\n",
    "- Face Shape: Round = 1, Not Round = 0\n",
    "- Whiskers: Present = 1, Absent = 0\n",
    "\n",
    "Therefore, we have two sets:\n",
    "\n",
    "- `X_train`: for each example, contains 3 features:\n",
    "            - Ear Shape (1 if pointy, 0 otherwise)\n",
    "            - Face Shape (1 if round, 0 otherwise)\n",
    "            - Whiskers (1 if present, 0 otherwise)\n",
    "            \n",
    "- `y_train`: whether the animal is a cat\n",
    "            - 1 if the animal is a cat\n",
    "            - 0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0384e9f6",
   "metadata": {},
   "source": [
    "#### Step 3: Import The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9967ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature variable\n",
    "X_train = np.array([[1, 1, 1],\n",
    "[0, 0, 1],\n",
    "[0, 1, 0],\n",
    "[1, 0, 1],\n",
    "[1, 1, 1],\n",
    "[1, 1, 0],\n",
    "[0, 0, 0],\n",
    "[1, 1, 0],\n",
    "[0, 1, 0],\n",
    "[0, 1, 0]])\n",
    "\n",
    "# Target or ground truth variable\n",
    "y_train = np.array([1, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
    "\n",
    "# Column names variable\n",
    "feature_cols = ['Ear shape', 'Face shape', 'Whiskers']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660f0a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#For instance, the first example\n",
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079269c",
   "metadata": {},
   "source": [
    "This means that the first example has a pointy ear shape, round face shape and it has whiskers and is the category of a cat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc4582",
   "metadata": {},
   "source": [
    "#### Step 4: Instantiate a Decision Tree Classifier Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d750c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284491a4",
   "metadata": {},
   "source": [
    "#### Step 5: Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a693e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8d4dc",
   "metadata": {},
   "source": [
    "#### Step 6: Predict Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c1de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict the response for dataset\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71de53a",
   "metadata": {},
   "source": [
    "#### Step 7: Evaluate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8b3fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4331f",
   "metadata": {},
   "source": [
    "#### Step 8: Visualise The Model & Statisics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b660783",
   "metadata": {},
   "source": [
    "On each node, we compute the information gain for each feature, then split the node on the feature with the higher information gain, by comparing the entropy of the node with the weighted entropy in the two splitted nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea15b69",
   "metadata": {},
   "source": [
    "So, the best feature to split is indeed the Ear Shape. Run the code below to see the split in action. You do not need to understand the following code block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvocationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m export_graphviz(clf, out_file=dot_data,  \n\u001b[32m      8\u001b[39m                 filled=\u001b[38;5;28;01mTrue\u001b[39;00m, rounded=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      9\u001b[39m                 special_characters=\u001b[38;5;28;01mTrue\u001b[39;00m,feature_names = feature_cols,class_names=[\u001b[33m'\u001b[39m\u001b[33mNon Cat\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mCat\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     10\u001b[39m graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_png\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimages/cat.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m Image(graph.create_png())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydotplus\\graphviz.py:1810\u001b[39m, in \u001b[36mDot.__init__.<locals>.<lambda>\u001b[39m\u001b[34m(path, f, prog)\u001b[39m\n\u001b[32m   1800\u001b[39m     f.\u001b[34m__doc__\u001b[39m = (\n\u001b[32m   1801\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m'''Refer to the docstring accompanying the'''\u001b[39;00m\n\u001b[32m   1802\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m''''create' method for more information.'''\u001b[39;00m\n\u001b[32m   1803\u001b[39m     )\n\u001b[32m   1805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m frmt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.formats + [\u001b[33m'\u001b[39m\u001b[33mraw\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m   1806\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__setattr__\u001b[39m(\n\u001b[32m   1807\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mwrite_\u001b[39m\u001b[33m'\u001b[39m + frmt,\n\u001b[32m   1808\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m path,\n\u001b[32m   1809\u001b[39m         f=frmt,\n\u001b[32m-> \u001b[39m\u001b[32m1810\u001b[39m         prog=\u001b[38;5;28mself\u001b[39m.prog: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1811\u001b[39m     )\n\u001b[32m   1813\u001b[39m     f = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m'\u001b[39m\u001b[33mwrite_\u001b[39m\u001b[33m'\u001b[39m + frmt]\n\u001b[32m   1814\u001b[39m     f.\u001b[34m__doc__\u001b[39m = (\n\u001b[32m   1815\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m'''Refer to the docstring accompanying the'''\u001b[39;00m\n\u001b[32m   1816\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m''''write' method for more information.'''\u001b[39;00m\n\u001b[32m   1817\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydotplus\\graphviz.py:1918\u001b[39m, in \u001b[36mDot.write\u001b[39m\u001b[34m(self, path, prog, format)\u001b[39m\n\u001b[32m   1915\u001b[39m         fobj.write(data)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m         fobj.write(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m   1919\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1920\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m close:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydotplus\\graphviz.py:1959\u001b[39m, in \u001b[36mDot.create\u001b[39m\u001b[34m(self, prog, format)\u001b[39m\n\u001b[32m   1957\u001b[39m     \u001b[38;5;28mself\u001b[39m.progs = find_graphviz()\n\u001b[32m   1958\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.progs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1959\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvocationException(\n\u001b[32m   1960\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mGraphViz\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33ms executables not found\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prog \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.progs:\n\u001b[32m   1963\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvocationException(\n\u001b[32m   1964\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mGraphViz\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33ms executable \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m not found\u001b[39m\u001b[33m'\u001b[39m % prog)\n",
      "\u001b[31mInvocationException\u001b[39m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = feature_cols,class_names=['Non Cat','Cat'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('images/cat.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final tree looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "#  - This is a custom module, built to visual this problem\n",
    "#  - Students should scroll past the code to see the visualisation\n",
    "import sys\n",
    "sys.path.insert(1, 'lib')\n",
    "from utils import *\n",
    "\n",
    "tree = []\n",
    "build_tree_recursive(X_train, y_train, [0,1,2,3,4,5,6,7,8,9], \"Root\", max_depth=2, current_depth=0, tree = tree)\n",
    "generate_tree_viz([0,1,2,3,4,5,6,7,8,9], y_train, tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "56d44d6a8424451b5ce45d1ae0b0b7865dc60710e7f74571dd51dd80d7829ee9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
